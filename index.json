[{"authors":["admin"],"categories":null,"content":"I am an assistant professor in the department of Computer Science at LSU Shreveport. My research interests lie primarily in the big-data domain of de novo whole genome assembly and in general I am intested in the high-performance computing (HPC) aspect of handling scientific datasets. I am especially interested in desiging scalable memory-efficient tools for processing large datasets by sketching, streaming or partitioning them.\nLately, I am quite keen on third generation sequence assembly (also known as long read assembly) partly because of the computational complexity involved in it but mostly since low-cost portable 3G sequencers such as Oxford Nanopore MinION can make personalized medicine, and on-field analysis, such as monitoring pathogens or environmental samples, much more affordable.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://sayangoswami.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am an assistant professor in the department of Computer Science at LSU Shreveport. My research interests lie primarily in the big-data domain of de novo whole genome assembly and in general I am intested in the high-performance computing (HPC) aspect of handling scientific datasets. I am especially interested in desiging scalable memory-efficient tools for processing large datasets by sketching, streaming or partitioning them.\nLately, I am quite keen on third generation sequence assembly (also known as long read assembly) partly because of the computational complexity involved in it but mostly since low-cost portable 3G sequencers such as Oxford Nanopore MinION can make personalized medicine, and on-field analysis, such as monitoring pathogens or environmental samples, much more affordable.","tags":null,"title":"Sayan Goswami","type":"authors"},{"authors":["Sayan Goswami","Kisung Lee","Shayan Shams","Seung-Jong Park"],"categories":null,"content":"","date":1533531600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533531600,"objectID":"0e1d9bf9de92b419ccd36973a1a6a960","permalink":"https://sayangoswami.github.io/publication/lasagna/","publishdate":"2018-08-06T00:00:00-05:00","relpermalink":"/publication/lasagna/","section":"publication","summary":"Spurred by a widening gap between hardware accelerators and traditional processors, numerous bioinformatics applications have harnessed the computing power of GPUs and reported substantial performance improvements compared to their CPU-based counterparts. However, most of these GPU-based applications only focus on the read alignment problem, while the field of de novo assembly still relies mostly on CPU-based solutions. This is primarily due to the nature of the assembly workload which is not only compute-intensive but also extremely data-intensive. Such workloads require large memories, making it difficult to adapt them to use GPUs with their limited memory capacities. To the best of our knowledge, no GPU-based assembler reported in the recent literature has attempted to assemble datasets larger than a few tens of gigabytes, whereas real sequence datasets are often several hundreds of gigabytes in size. In this paper, we present a new GPU-accelerated genome assembler called LaSAGNA, which can assemble large-scale sequence datasets using a single GPU by building string graphs from approximate all-pair overlaps. LaSAGNA can also run on multiple GPUs across multiple compute nodes connected by a high-speed network to expedite the assembly process. To utilize the limited memory on GPUs efficiently, LaSAGNA uses a semi-streaming approach that makes at most a logarithmic number of passes over the input data based on the available memory. Moreover, we propose a two-level streaming model, from disk to host memory and from host memory to device memory, to minimize disk I/O. Using LaSAGNA, we can assemble a 400 GB human genome dataset on a single NVIDIA K40 GPU in 17 hours, and in a little over 5 hours on an 8-node cluster of NVIDIA K20s.","tags":[],"title":"GPU-Accelerated Large-Scale Genome Assembly","type":"publication"},{"authors":["Shayan Shams","Sayan Goswami","Kisung Lee","Seungwon Yang","Seung-Jong Park"],"categories":null,"content":"","date":1532322000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532322000,"objectID":"d12bbe192a5125f644fb58d898799f89","permalink":"https://sayangoswami.github.io/publication/icdcs/","publishdate":"2018-07-23T00:00:00-05:00","relpermalink":"/publication/icdcs/","section":"publication","summary":"Recent advances in big data and deep learning technologies have enabled researchers across many disciplines to gain new insight into large and complex data. For example, deep neural networks are being widely used to analyze various types of data including images, videos, texts, and time-series data. In another example, various disciplines such as sociology, social work, and criminology are analyzing crowd-sourced and online social network data using big data technologies to gain new insight from a plethora of data. Even though many different types of data are being generated and analyzed in various domains, the development of distributed city-level cyberinfrastructure for effectively integrating such data to generate more value and gain insights is still not well-addressed in the research literature. In this paper, we present our current efforts and ultimate vision to build distributed cyberinfrastructure which integrates big data and deep learning technologies with a variety of data for enhancing public safety and livability in cites. We also introduce several methodologies and applications that we are developing on top of the cyberinfrastructure to support diverse community stakeholders in cities.","tags":[],"title":"Towards Distributed Cyberinfrastructure for Smart Cities Using Big Data and Deep Learning Technologies","type":"publication"},{"authors":null,"categories":null,"content":"","date":1516406400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1516406400,"objectID":"9cf52edb5c9250a8cedd997b3288d364","permalink":"https://sayangoswami.github.io/teaching/csc285_f18/","publishdate":"2018-01-20T00:00:00Z","relpermalink":"/teaching/csc285_f18/","section":"teaching","summary":"Introduction to object-oriented design, design patterns,and design tools.","tags":null,"title":"CSC285","type":"teaching"},{"authors":["Arghya Kusum Das","Jaeki Hong","Sayan Goswami","Richard Platania","Kisung lee","Wooseok Chang","Seung-Jong Park","Ling Liu"],"categories":null,"content":"","date":1505106000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505106000,"objectID":"c099ad599effe86e90d5fc4314e9eb82","permalink":"https://sayangoswami.github.io/publication/cloud/","publishdate":"2017-09-11T00:00:00-05:00","relpermalink":"/publication/cloud/","section":"publication","summary":"High-performance analysis of big data demands more computing resources, forcing similar growth in computation cost. So, the challenge to the HPC system designers is providing not only high performance but also high performance at lower cost. For high performance yet cost effective cyberinfrastructure, we propose a new system model augmenting Amdahl's second law for balanced system to optimize price-performance-ratio. We express the optimal balance among CPU-speed, I/O-bandwidth and DRAM-size (i.e., Amdahl's I/O-and memory-number) in terms of application characteristics and hardware cost. Considering Xeon processor and recent hardware prices, we showed that a system needs almost 0.17GBPS I/O-bandwidth and 3GB DRAM per GHz CPU-speed to minimize the price-performance-ratio for data-and compute-intensive applications. To substantiate our claim, we evaluate three different cluster architectures: 1) SupermikeII, a traditional HPC cluster, 2) SwatIII, a regular datacenter, and 3) CeresII, a MicroBrick-based novel hyperscale system. CeresII with 6-Xeon-D1541 cores (2GHz/core), 1-NVMe SSD (2GBPS I/O-bandwidth) and 64GB DRAM per node, closely resembles the optimum produced by our model. Consequently, in terms of price-performance-ratio CeresII outperformed both SupermikeII (by 65-85%) and SwatIII (by 40-50%) for data-and compute-intensive Hadoop benchmarks (TeraSort and WordCount) and our own benchmark genome assembler based on Hadoop and Giraph.","tags":[],"title":"Augmenting Amdahl's Second Law: A Theoretical Model to Build Cost-Effective Balanced HPC Infrastructure for Data-Driven Science","type":"publication"},{"authors":["Sayan Goswami","Arghya Kusum Das","Richard PÅ‚atania","Kisung Lee","Seung-Jong Park"],"categories":null,"content":"","date":1480917600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1480917600,"objectID":"66f646b7e3492e13c2f1a23228d7b12d","permalink":"https://sayangoswami.github.io/publication/lazer/","publishdate":"2016-12-05T00:00:00-06:00","relpermalink":"/publication/lazer/","section":"publication","summary":"Genome sequencing technology has witnessed tremendous progress in terms of throughput as well as cost per base pair, resulting in an explosion in the size of data. Consequently, typical sequence assembly tools demand a lot of processing power and memory and are unable to assemble big datasets unless run on hundreds of nodes. In this paper, we present a distributed assembler that achieves both scalability and memory efficiency by using partitioned de Bruijn graphs. By enhancing the memory-to-disk swapping and reducing the network communication in the cluster, we can assemble large sequences such as human genomes (452 GB) on just two nodes in 14.5 hours, and also scale up to 128 nodes in 23 minutes. We also assemble a synthetic wheat genome with 1.1 TB of raw reads on 8 nodes in 18.5 hours and on 128 nodes in 1.25 hours.","tags":[],"title":"Lazer: Distributed memory-efficient assembly of large-scale genomes","type":"publication"}]